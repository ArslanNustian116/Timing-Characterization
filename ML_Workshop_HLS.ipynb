{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN0gGkN7A4AQnMBe5rsElUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArslanNustian116/Timing-Characterization/blob/main/ML_Workshop_HLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzU-6vcYN6sY"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.random.set_seed(seed)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fetch Jet Tagging Dataset"
      ],
      "metadata": {
        "id": "kUzrQzCEQ2dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
        "X, y = data['data'], data['target']\n",
        "\n",
        "print(data['feature_names'])\n",
        "print(X.shape, y.shape)\n",
        "print(X[:5])\n",
        "print(y[:5])\n",
        "\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "y = to_categorical(y, 5)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(y[:5])\n",
        "scaler = StandardScaler()\n",
        "X_train_val = scaler.fit_transform(X_train_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "np.save('X_train_val.npy', X_train_val)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train_val.npy', y_train_val)\n",
        "np.save('y_test.npy', y_test)\n",
        "np.save('classes.npy', le.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcAkAsADPJPz",
        "outputId": "ae8494cc-b4a4-4a00-b6ed-0674fe39cad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['zlogz', 'c1_b0_mmdt', 'c1_b1_mmdt', 'c1_b2_mmdt', 'c2_b1_mmdt', 'c2_b2_mmdt', 'd2_b1_mmdt', 'd2_b2_mmdt', 'd2_a1_b1_mmdt', 'd2_a1_b2_mmdt', 'm2_b1_mmdt', 'm2_b2_mmdt', 'n2_b1_mmdt', 'n2_b2_mmdt', 'mass_mmdt', 'multiplicity']\n",
            "(830000, 16) (830000,)\n",
            "      zlogz  c1_b0_mmdt  c1_b1_mmdt  c1_b2_mmdt  c2_b1_mmdt  c2_b2_mmdt  \\\n",
            "0 -2.935125    0.383155    0.005126    0.000084    0.009070    0.000179   \n",
            "1 -1.927335    0.270699    0.001585    0.000011    0.003232    0.000029   \n",
            "2 -3.112147    0.458171    0.097914    0.028588    0.124278    0.038487   \n",
            "3 -2.666515    0.437068    0.049122    0.007978    0.047477    0.004802   \n",
            "4 -2.484843    0.428981    0.041786    0.006110    0.023066    0.001123   \n",
            "\n",
            "   d2_b1_mmdt  d2_b2_mmdt  d2_a1_b1_mmdt  d2_a1_b2_mmdt  m2_b1_mmdt  \\\n",
            "0    1.769445    2.123898       1.769445       0.308185    0.135687   \n",
            "1    2.038834    2.563099       2.038834       0.211886    0.063729   \n",
            "2    1.269254    1.346238       1.269254       0.246488    0.115636   \n",
            "3    0.966505    0.601864       0.966505       0.160756    0.082196   \n",
            "4    0.552002    0.183821       0.552002       0.084338    0.048006   \n",
            "\n",
            "   m2_b2_mmdt  n2_b1_mmdt  n2_b2_mmdt   mass_mmdt  multiplicity  \n",
            "0    0.083278    0.412136    0.299058    8.926882          75.0  \n",
            "1    0.036310    0.310217    0.226661    3.886512          31.0  \n",
            "2    0.079094    0.357559    0.289220  162.144669          61.0  \n",
            "3    0.033311    0.238871    0.094516   91.258934          39.0  \n",
            "4    0.014450    0.141906    0.036665   79.725777          35.0  \n",
            "0    g\n",
            "1    w\n",
            "2    t\n",
            "3    z\n",
            "4    w\n",
            "Name: class, dtype: category\n",
            "Categories (5, object): ['g', 'q', 't', 'w', 'z']\n",
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import callbacks\n",
        "\n",
        "X_train_val = np.load('X_train_val.npy')\n",
        "X_test = np.load('X_test.npy')\n",
        "y_train_val = np.load('y_train_val.npy')\n",
        "y_test = np.load('y_test.npy')\n",
        "classes = np.load('classes.npy', allow_pickle=True)\n"
      ],
      "metadata": {
        "id": "c5fOcZmZOD1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a Base Line Model"
      ],
      "metadata": {
        "id": "bNS3TkDRRBHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from callbacks import all_callbacks\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_shape=(16,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu1'))\n",
        "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu2'))\n",
        "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='relu', name='relu3'))\n",
        "model.add(Dense(5, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
        "model.add(Activation(activation='softmax', name='softmax'))"
      ],
      "metadata": {
        "id": "hMpS5EAHORzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Baseline Model"
      ],
      "metadata": {
        "id": "PoyThhXqRWFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_1',\n",
        "    )\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    model = load_model('model_1/KERAS_check_best_model.h5')"
      ],
      "metadata": {
        "id": "3acRclO2RZdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-model-optimization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaG1l2iKQy8W",
        "outputId": "bc90b5a9-9b21-4a32-f892-bdff7fbe54a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.25.2)\n",
            "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Installing collected packages: tensorflow-model-optimization\n",
            "Successfully installed tensorflow-model-optimization-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Pruning Parameters"
      ],
      "metadata": {
        "id": "X819j75bRG5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
        "model = prune.prune_low_magnitude(model, **pruning_params)"
      ],
      "metadata": {
        "id": "qQNY0l10OS7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Pruned Model"
      ],
      "metadata": {
        "id": "NPrrf2KgRc8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_2',\n",
        "    )\n",
        "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
        "    model = strip_pruning(model)\n",
        "    model.save('model_2/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "\n",
        "    model = load_model('model_2/KERAS_check_best_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ICX1429OXyC",
        "outputId": "c01a8aa6-4686-4d64-83cd-f210d95c24fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Observing the Weights after Pruning"
      ],
      "metadata": {
        "id": "01AI8aJYSGo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = model.layers[0].weights[0].numpy()\n",
        "h, b = np.histogram(w, bins=100)\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.bar(b[:-1], h, width=b[1] - b[0])\n",
        "plt.semilogy()\n",
        "print('% of zeros = {}'.format(np.sum(w == 0) / np.size(w)))"
      ],
      "metadata": {
        "id": "Zt9m32nPUszo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Accuracy of Baseline and Pruned Model"
      ],
      "metadata": {
        "id": "mxJzNxFkSSER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_ref = load_model('model_1/KERAS_check_best_model.h5')\n",
        "\n",
        "y_ref = model_ref.predict(X_test)\n",
        "y_prune = model.predict(X_test)\n",
        "\n",
        "print(\"Accuracy unpruned: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
        "print(\"Accuracy pruned:   {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_prune, axis=1))))\n"
      ],
      "metadata": {
        "id": "KBRkM6XSWjpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create HLS Project"
      ],
      "metadata": {
        "id": "lP7RXnhoSbV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hls4ml\n",
        "\n",
        "import hls4ml\n",
        "\n",
        "config = hls4ml.utils.config_from_keras_model(model, granularity='model')\n",
        "print(config)\n",
        "hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "    model, hls_config=config, output_dir='model_2/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        ")\n",
        "hls_model.compile()\n"
      ],
      "metadata": {
        "id": "98yQsKZtZtYA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "f319367b-214f-4969-fdad-69ba72e9193a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hls4ml\n",
            "  Downloading hls4ml-0.8.1-py3-none-any.whl (572 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.3/572.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'hls4ml'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-b7e6c24f18ff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install hls4ml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhls4ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhls4ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_from_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hls4ml'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Quantized Model"
      ],
      "metadata": {
        "id": "jweahza-SrK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from callbacks import all_callbacks\n",
        "from tensorflow.keras.layers import Activation\n",
        "from qkeras.qlayers import QDense, QActivation\n",
        "from qkeras.quantizers import quantized_bits, quantized_relu\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(\n",
        "    QDense(\n",
        "        64,\n",
        "        input_shape=(16,),\n",
        "        name='fc1',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc2',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        32,\n",
        "        name='fc3',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
        "model.add(\n",
        "    QDense(\n",
        "        5,\n",
        "        name='output',\n",
        "        kernel_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        bias_quantizer=quantized_bits(6, 0, alpha=1),\n",
        "        kernel_initializer='lecun_uniform',\n",
        "        kernel_regularizer=l1(0.0001),\n",
        "    )\n",
        ")\n",
        "model.add(Activation(activation='softmax', name='softmax'))\n",
        "\n",
        "\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
        "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
        "\n",
        "pruning_params = {\"pruning_schedule\": pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
        "model = prune.prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "train = True\n",
        "if train:\n",
        "    adam = Adam(lr=0.0001)\n",
        "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
        "    callbacks = all_callbacks(\n",
        "        stop_patience=1000,\n",
        "        lr_factor=0.5,\n",
        "        lr_patience=10,\n",
        "        lr_epsilon=0.000001,\n",
        "        lr_cooldown=2,\n",
        "        lr_minimum=0.0000001,\n",
        "        outputDir='model_3',\n",
        "    )\n",
        "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
        "    model.fit(\n",
        "        X_train_val,\n",
        "        y_train_val,\n",
        "        batch_size=1024,\n",
        "        epochs=30,\n",
        "        validation_split=0.25,\n",
        "        shuffle=True,\n",
        "        callbacks=callbacks.callbacks,\n",
        "    )\n",
        "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
        "    model = strip_pruning(model)\n",
        "    model.save('model_3/KERAS_check_best_model.h5')\n",
        "else:\n",
        "    from tensorflow.keras.models import load_model\n",
        "    from qkeras.utils import _add_supported_quantized_objects\n",
        "\n",
        "    co = {}\n",
        "    _add_supported_quantized_objects(co)\n",
        "    model = load_model('model_3/KERAS_check_best_model.h5', custom_objects=co)\n",
        "\n",
        "\n",
        "import hls4ml\n",
        "\n",
        "config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
        "config['LayerName']['softmax']['exp_table_t'] = 'ap_fixed<18,8>'\n",
        "config['LayerName']['softmax']['inv_table_t'] = 'ap_fixed<18,4>'\n",
        "print(\"-----------------------------------\")\n",
        "hls_model = hls4ml.converters.convert_from_keras_model(\n",
        "    model, hls_config=config, output_dir='model_3/hls4ml_prj', part='xcu250-figd2104-2L-e'\n",
        ")\n",
        "hls_model.compile()\n",
        "\n",
        "y_qkeras = model.predict(np.ascontiguousarray(X_test))\n",
        "y_hls = hls_model.predict(np.ascontiguousarray(X_test))\n",
        "np.save('model_3/y_qkeras.npy', y_qkeras)\n",
        "np.save('model_3/y_hls.npy', y_hls)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "klvY2Omyc-QZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_ref = load_model('model_1/KERAS_check_best_model.h5')\n",
        "y_ref = model_ref.predict(X_test)\n",
        "\n",
        "print(\"Accuracy baseline:  {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_ref, axis=1))))\n",
        "print(\"Accuracy pruned, quantized: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_qkeras, axis=1))))\n",
        "print(\"Accuracy hls4ml: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))"
      ],
      "metadata": {
        "id": "DB5DEv5pg2Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "js-hM7LrhChY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}